% !TeX encoding = ISO-8859-1
\chapter{Integración del Sistema}
%\blindtext
\section{Implementación del Área Funcional Estructura}

La resolución de esta área funcional está relacionada con el armado del robot, que como ya se había mencionado con anterioridad en capítulos pasados, esta área funcional tiene como requerimiento principal el albergar a todas las demás áreas funcionales, lo cual no presentó mayor dificultad porque cada robot ya viene diseñado para únicamente armar y centrarse en desarrollar el algoritmo de control \textit{líder - seguidor}. 

\subsection{Recomendaciones a considerar}

Para el armado de la estructura y de las partes electrónicas se siguieron las instrucciones tal y como se indican en el manual de ensamble del TurtleBot3 burger \cite{e-Manual-structure}, con algunos consejos que a continuación se mencionan.

\begin{itemize}
	\item Antes de armar el TurtleBot3 burger tener todo el software de inicio instalado.
	\item En el caso particular de la Raspberry Pi 3, usar un cargador de 5.0V a 2A (al menos) para instalar el sistema operativo.
	\item Ir verificando que cada capa este bien ensamblada.
	\item Hacer pruebas de hardware para cada capa.
	\item Armarla en un lugar seguro en cual no pierdan piezas pequeñas.
	\item Consultar el video de armado para un mejor armado.
\end{itemize}

\subsection{Armado de los robots móviles}

%%Caja de los diferentes componentes del robot.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.40]{imagenes/Implementacion/Estructura/01_Caja_de_Componentes.jpg}}
	\caption{Caja con los diferentes componentes del robot.}
	\label{fig:Figura_Caja_Componentes}
\end{figure}

Los componentes del TurtleBot3 burger vienen en 4 cajas enumeradas y mostradas en la \textit{Figura \ref{fig:Figura_Caja_Componentes}}, cada caja cuenta con distintas piezas y componentes. En la \textit{caja 1} como se muestra en la \textit{Figura \ref{fig:Figura_Caja_1}}, viene una tarjeta microSD de 16GB, una tarjeta Raspberry Pi 3, un par de motores Dynamixel y una tarjeta OpenCR Cortex M7. En la \textit{caja 2} mostrada en la \textit{Figura \ref{fig:Figura_Caja_2}} viene una batería LiPo junto con su cargador, un desarmador, un sensor LIDAR, un conector USB2LDS y soportes para pcb's. 
En la \textit{caja 3} como se muestra en la \textit{Figura \ref{fig:Figura_Caja_3}} vienen todos los pisos del robot denominados ``Waffle - Plate". En la \textit{caja 4} mostrada en la \textit{Figura \ref{fig:Figura_Caja_4}} viene el sistema de tracción, es decir, las llantas con sus respectivas ruedas, tornillos y piezas de ensamble de todo el robot, cables y una rueda loca.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.225]{imagenes/Implementacion/Estructura/02_Caja_1.jpg}}
	\caption{Caja 1. \textit{MicroSD, Raspberry Pi 3, motores Dynamixel y tarjeta OpenCR Cortex M7}}
	\label{fig:Figura_Caja_1}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.225]{imagenes/Implementacion/Estructura/03_Caja_2.jpg}}
	\caption{Caja 2. \textit{Batería LiPo, cargador, desarmador, sensor LIDAR, conector USB2LDS y soportes para pcb's}}
	\label{fig:Figura_Caja_2}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/Estructura/04_Caja_3.jpg}}
	\caption{Caja 3.\textit{``Waffle - Plate" pisos de los robots}}
	\label{fig:Figura_Caja_3}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/Estructura/05_Caja_4.jpg}}
	\caption{Caja 4. \textit{Llantas, ruedas, tornillos, piezas de ensamble, cables y una rueda loca}}
	\label{fig:Figura_Caja_4}
\end{figure}

Además de estas cuatro cajas, hay una caja más, no numerada donde viene la fuente de voltaje para el cargador con su respectivo cable.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.30]{imagenes/Implementacion/Estructura/06_Fuente_de_carga.jpg}}
	\caption{Fuente de voltaje para batería LiPo.}
	\label{fig:Figura_Fuente_de_carga}
\end{figure}

La primera parte del armado consiste en unir cada uno de los pisos con ayuda de sus respectivos tornillos, así como también de sus distintos componentes, tal y como se muestra en las \textit{Figuras \ref{fig:Figura_Uniones}} y \textit{\ref{fig:Figura_Wafles_Ensamblados}}.

%%Unión de los pisos del robot.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.40]{imagenes/Implementacion/Estructura/07_Uniones.jpg}}
	\caption{Unión de los pisos del robot.}
	\label{fig:Figura_Uniones}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.28]{imagenes/Implementacion/Estructura/08_Wafles_Ensamblados.jpg}}
	\caption{Piezas Ensambladas.}
	\label{fig:Figura_Wafles_Ensamblados}
\end{figure}

Caber mencionar que a pesar de que en el instructivo de armado viene paso por paso, como van las piezas y cada una de las tapas, muchas veces este no es tan claro, aunado a que todas las partes del robot son muy parecidas, dando lugar a piezas mal colocadas y por ende mal ensambladas a la hora de unir cada uno de los pisos.

%%Ensamble del robot.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.42]{imagenes/Implementacion/Estructura/09_Ensamble_Robot.jpg}}
	\caption{Ensamble del robot.}
	\label{fig:Figura_Ensamble_Robot}
\end{figure}

\subsection{Resultados del proceso de armado}

En las \textit{Figuras \ref{fig:Figura_Piso_1}, \ref{fig:Figura_Piso_2}, \ref{fig:Figura_Piso_3}} y \textit{\ref{fig:Figura_Ensamble_Final}} se puede observar la manera en que se ven cada uno de los pisos del TurtleBot3 burger, así como también el orden en el que son ensamblados.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/Estructura/10_Piso_1.jpg}}
	\caption{Ensamble del primer piso.}
	\label{fig:Figura_Piso_1}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/Estructura/11_Piso_2.jpg}}
	\caption{Ensamble del segundo piso.}
	\label{fig:Figura_Piso_2}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.235]{imagenes/Implementacion/Estructura/12_Piso_03.jpg}}
	\caption{Ensamble del tercer piso.}
	\label{fig:Figura_Piso_3}
\end{figure}

%%Ensamble final del robot.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=1.5425]{imagenes/Implementacion/Estructura/13_Ensamble_Final.jpg}}
	\caption{Ensamble final del robot.}
	\label{fig:Figura_Ensamble_Final}
\end{figure}

El armado de cada robot representa un trabajo muy minucioso, ya que cada tornillo y tuerca tienen que estar en el lugar adecuado, cada piso y componente bien encajados y posicionados, dificultándose porque algunas piezas son de ensamble múltiple por lo que, si se mueve una, se tiene que reiniciar el proceso de ensamblaje. El proceso de ensamblaje duró aproximadamente 5 horas de trabajo continuo para cada TurtleBot3.

%%Robots Líder ? Seguidor.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=2.0]{imagenes/Implementacion/Estructura/14_Robots_Lider_Seguidor.jpg}}
	\caption{Robot líder y robot seguidor.}
	\label{fig:Figura_Robots_Lider_Seguidor}
\end{figure}

\subsection{Verificación de ensamble del sistema}

Una vez que el robot estuvo armado, se verificó que todo estuviera bien conectado, es decir, que la batería LiPo alimentara a las dos tarjetas de procesamiento (Raspberry y OpenCR) y que estas a su vez alimentaran a los subsistemas que de ellas dependen como los actuadores y el sensor LIDAR. El trabajo en conjunto del ensamble del robot junto con la programación e instalación del sistema operativo Raspbian a la Raspberry Pi 3 también proporcionó herramientas de validación para saber el estado de los elementos conectados a los móviles.

\section{Implementación del Área Funcional Movimiento}

Esta área funcional es la encargada de la unión de la estructura junto con su configuración mecánica. En la implementación se utilizan 2 actuadores Dynamixel por cada robot, conectados a una tarjeta OpenCR denominada tarjeta de control. Para ajustar el controlador PID encargado de mantener estable las velocidades de los robots, no es necesario realizar un cálculo de valores, ya que los motores cuentan con la opción de \textit{autotune} que permite de forma automática, obtener los valores del controlador PID necesarios para lograr un control de velocidad y estos ya están previamente configurados, con un valor \textbf{P} de 1.1, \textbf{D} de 0.03 e \textbf{I} de 0.11. 

En la \textit{Figura \ref{fig:Figura_Area movimientos}} se muestra el ensamble mínimo para poder verificar el área funcional de movimiento usando los botones de la tarjeta OpenCR para controlar el movimiento del móvil.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/Estructura/11_Piso_2.jpg}}
	\caption{Implementación del área funcional movimiento.}
	\label{fig:Figura_Area movimientos}
\end{figure}

\section{Implementación del Área Funcional Percepción}

En la implementación de la tercera área funcional, se utilizan 2 sensores; el LIDAR y el encoder del actuador, que en conjunto logran percibir el entorno brindando así la posibilidad de conocer la posición de cada robot y determinar los elementos presentes en el área de trabajo, obstáculos, límites, paredes, etc. 

\subsection{Sensor LIDAR}

El primer sensor involucrado es el sensor LIDAR, que por medio de este sensor se miden las distancias mínimas de la cercanía, hacia algún objeto (en el caso del proyecto puede ser una pared o un obstáculo), calculando así las distancias mínimas para cada uno de los 360 grados que rodean al robot.

\break

Para su implementación este sensor fue colocado en la capa superior de cada robot como se observa en \textit{Figura \ref{fig:Figura_Montaje_LIDAR}}, teniendo en cuenta que cada sensor es independiente el uno del otro, y al verificar su correcto funcionamiento en los robots, se deben aplicar los mismos pasos para cada uno de ellos. Posteriormente se realizan las pruebas en la interfaz gráfica proporcionada por el fabricante (previamente realizadas las configuraciones básicas del TurtleBot3 que se explican a detalle en la sección de Procesamiento) arrojando como resultados las distancias reflejadas en un mapa 2D del sensor LIDAR, comprobando así, su correcto funcionamiento.

%%Ilustración 1: Montaje del sensor LIDAR en la estructura
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.45]{imagenes/Implementacion/01_Montaje_LIDAR.jpg}}
	\caption{Montaje del sensor LIDAR en la estructura.}
	\label{fig:Figura_Montaje_LIDAR}
\end{figure}
Como se puede observar en la \textit{Figura \ref{fig:Figura_Montaje_LIDAR}} se debe cuidar la orientación en la que se coloca el sensor LIDAR, colocándolo de tal forma como se muestra en la \textit{Figura \ref{fig:Figura_Montaje_LIDAR}}, ya que el sistema de referencia entre el robot y los datos arrojados en la interfaz son propuestos, considerando que el sensor LIDAR tiene su origen en 0 grados en la parte frontal del robot.

Al no respetarse esta condición da como resultado un desfasamiento en el ángulo, afectando la realización del mapa del entorno y que posteriormente viéndose reflejado en un desfase angular en los demás robots que no tengan la misma orientación que el robot que realizó el escaneo del mapa.

\break

Es importante también señalar que el sensor LIDAR cuenta al frente con un indicador de fase, el cual le comunica al controlador del LIDAR que ha pasado por el 0 absoluto del sensor, realizándose esto cada que se inicia un nuevo proceso de escaneo ya que no se sabe con certeza en que posición está apuntando el del sensor LIDAR en un inicio. 

%%Ilustración 2: Sensor LIDAR del Turtlebot 3 burger
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/02_LIDAR_tb3.jpg}}
	\caption{Sensor LIDAR del Turtlebot 3 burger.}
	\label{fig:Figura_Sensor_LIDAR_tb3}
\end{figure}
Para comprobar que el sensor está funcionando correctamente se cuenta con un programa que inicializa los nodos necesarios para el funcionamiento básico del robot, el cual comunica el robot con la computadora principal, además de obtener y mandar datos al sensor LIDAR y a los motores, por medio de la tarjeta OpenCR.

Las instrucciones para correr esta verificación son las siguientes.

\begin{itemize}
	\item roscore (En la PC principal)
	\item roslaunch turtlebot3 turtlebot3\_bringup.launch (En la Raspberry Pi 3)
	\item roslaunch turtlebot3\_slam turtlebot3\_slam.launch (En la PC principal)
\end{itemize}

Al correr estos comandos, habiendo configurado correctamente la comunicación entre el TurtleBot3 y la PC principal, se obtienen los resultados mostrados en la \textit{Figura \ref{fig:Figura_Distancias_LIDAR_RVIZ}}, donde los puntos en verde son las distancias escaneadas por el LIDAR.

%%Ilustración 3: Distancias del LIDAR en RVIZ
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.335]{imagenes/Implementacion/03_RVIZ_Distancias.jpg}}
	\caption{Distancias del LIDAR en RVIZ}
	\label{fig:Figura_Distancias_LIDAR_RVIZ}
\end{figure}


Adicionalmente se pueden ver los valores de las distancias si se ejecuta el comando:

\begin{itemize}
	\item rqt (En la PC principal)
\end{itemize}

Al abrirse la ventana como se muestra en la \textit{Figura \ref{fig:Figura_RQt_LIDAR_scan}} se pueden observar los valores de los mensajes publicados, y marcándose la casilla se pueden leer y ver su valor en la pantalla. Para verificar los datos que arroja el sensor se marca la casilla /scan, en donde si no aparece nada significa que se tiene problemas con el sensor LIDAR o la ejecución de los comandos ha sido incorrecta.

%%Ilustración 4: Visualización en rqt de los valores del sensor LIDAR
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.355]{imagenes/Implementacion/04_RQt_scan.jpg}}
	\caption{Visualización en rqt de los valores del sensor LIDAR.}
	\label{fig:Figura_RQt_LIDAR_scan}
\end{figure}

\subsection{Sensores del motor DYNAMIXEL}

El segundo sensor involucrado es el encoder contenido en los motores DYNAMIXEL mostrado en la \textit{Figura \ref{fig:Figura_Motores_DYNAMIXEL_XL430}}, este enconder lleva a cabo la tarea en conjunto con el microcontrolador del motor, de estimar el desplazamiento que ha tenido el robot.

%%Ilustración 5: Motores DYNAMIXEL XL430
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.215]{imagenes/Implementacion/05_Dynamixel.jpg}}
	\caption{Motores DYNAMIXEL XL430.}
	\label{fig:Figura_Motores_DYNAMIXEL_XL430}
\end{figure}

Para la implementación de este sensor se colocan los 2 motores en la estructura conectados a la tarjeta OpenCR como se muestra en la \textit{Figura \ref{fig:Figura_Ensamble_motores_OpenCR}}.

%%Ilustración 6: Ensamble de los motores, OpenCR y Bateria LiPo
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/06_OpenCR_Dynamixel.jpg}}
	\caption{Ensamble de los motores, OpenCR y batería LiPo.}
	\label{fig:Figura_Ensamble_motores_OpenCR}
\end{figure}

Una vez ensamblada esa capa, se procede a verificar el funcionamiento de los motores, así como el funcionamiento de los enconders por medio del programa base que se carga a la OpenCR. Este programa hace dos pruebas con los motores; una para lograr un desplazamiento lineal y otra para lograr un desplazamiento angular (giro de 180° conforme al centro del robot) en la posición del robot.

%%Ilustración 7: Localización de los botones de prueba en la tarjeta OpenCR
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/07_OpenCR_botones.jpg}}
	\caption{Localización de los botones de prueba en la tarjeta OpenCR.}
	\label{fig:Figura_Botones_OpenCR}
\end{figure}

El proceso de verificación del correcto funcionamiento de los encoders y el giro de los motores es el siguiente:

\begin{itemize}
	\item Revisar que todos los elementos estén ensamblados al menos hasta la capa 2.
	\item Encender el robot por medio del switch que trae consigo la tarjeta Open CR.
	\item Presionar por 3 segundos el botón PUSH SW1 visto en la \textit{Figura \ref{fig:Figura_Botones_OpenCR}} para verificar que el robot avance alrededor de 30 cm.
	\item Presionar por 3 segundos el botón PUSH SW2 visto en la \textit{Figura \ref{fig:Figura_Botones_OpenCR}} para verificar que el robot gire 180° grados sobre su propio eje.
\end{itemize}

Si estas 2 pruebas se cumplen entonces los encoders están funcionando correctamente.

\section{Implementación del Área Funcional Alimentación}
Para la implementación de esta área funcional se hace uso de una batería LiPo de 11.1V y 1800mAH, vista en la \textit{Figura \ref{fig:Figura_Bateria_LiPo_LB012}}, la cual logra una carga total en aproximadamente en una hora y media de haberse puesto a cargar, y es capaz de mantener en operación al robot por aproximadamente 2 horas en funcionamiento de uso moderado.

%%Batería LiPo LB-012
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.27]{imagenes/Implementacion/08_Bateria_LiPo.jpg}}
	\caption{Batería LiPo LB-012.}
	\label{fig:Figura_Bateria_LiPo_LB012}
\end{figure}

Para verificar su correcto funcionamiento solamente se conecta al móvil siguiendo los primeros pasos de ensamble que se muestran en la \textit{Figura \ref{fig:Figura_Ensamble_motores_OpenCR}} y se verifica que el Power LED de la OpenCR esté prendido, este LED se muestra en la \textit{Figura \ref{fig:Figura_Botones_OpenCR}}.

\section{Implementación del Área Funcional Procesamiento}

\subsection{Pasos previos}

Se requiere una configuración previa de las tarjetas de procesamiento de los robots y de la computadora remota. Todos los pasos necesarios para tener en el correcto funcionamiento a los TurtleBot3, se encuentran en su manual online.

\break

A continuación, se presentan algunos pasos adicionales que se deben realizar.\\

En la computadora remota se debe instalar \textit{Ubuntu 16.04}. Hay muchos tutoriales que explican cómo hacerlo y dependiendo de la computadora, puede ser más o menos complejo, una buena fuente de referencia es la de la página web \textit{linuxtechi \cite{install_ubuntu}}, aunque la mejor forma de instalar ROS en una computadora remota es bajo el método que propone el manual online de los TurtleBot3, donde todo el proceso ya es automático, proporcionando un script que va ejecutando los pasos de manera secuencial a diferencia de los métodos convencionales, donde es necesario ejecutar una serie de comandos manualmente.\\

Para la Raspberry Pi 3 existen dos sistemas operativos compatibles con ROS; \textit{Raspbian} y \textit{UbuntuMate}. Para el desarrollo del proyecto se ha optado por elegir Raspbian, ya que la forma de configurar el SSH está bien establecida en la documentación oficial de la Raspberry Pi \cite{ssh}, y además de que se proporciona una versión de Raspbian con ROS ya instalada en el mismo manual online, lo cual reduce en aproximadamente 2 horas el tiempo de instalación por cada tarjeta.\\

Para la OpenCR de igual manera existen dos formas de configurarla, la primera manera es por medio de la computadora remota, siendo más útil cuando se está ensamblando el robot por primera vez. La segunda manera es directamente desde la Raspberry Pi 3, siendo más sugerible esta opción cuando ya se tiene ensamblado el TurtleBot3, puesto que no se tiene que desconectar, ni desarmar ninguno de los pisos para poder llevar a cabo este proceso en la Raspberry Pi 3, basta con solo ejecutar el siguiente comando para que comience la descarga e instalación del programa.\\

https://github.com/ROBOTIS-GIT/OpenCR-Binaries/raw/master/turtlebot3/ROS1
/latest/opencr\_update.tar.bz2\&\& tar -xvf opencr\_update.tar.bz2
\&\& cd ./opencr\_update \&\& ./update.sh \$OPENCR\_PORT \$OPENCR\_MODEL.opencr \&\& cd ..
\\

Lo siguiente en implementar es la simulación del modelo 3D del ambiente en el que los robots de manera virtual serán simulados. Para ello se utiliza Gazebo y se selecciona la figura que se asemeja a una pared, trazándola con las medias correctas y modificando su aspecto visual para finalmente guardar el diseño.

También es necesario configurar RViz para poder visualizar los datos de los dos robots en el mismo tiempo de ejecución. La manera de configurar RViz es editando el archivo base que proporcionan las librerías del TurtleBot3 y eliminando algunos tópicos que no son necesarios, los cuales son:

\begin{itemize}
	\item /cost\_map
	\item /global\_cost\_map
\end{itemize}

Además, se deben agregar los tópicos del seguidor, que a continuación se enlistan:

\begin{itemize}
	\item /tb3\_1/robot\_model
	\item /tb3\_1/laser
	\item /tb3\_1/amcl\_particles
\end{itemize}

Adicionalmente en conjunto con el AMCL, se realiza el mapa del ambiente virtual y del espacio real, esto con el fin de obtener la posición de los robots con ayuda de los sensores. Los comandos que también están presentes en el manual y que se ejecutan sobre la terminal de la computadora remota son:

\begin{itemize}
	\item roslaunch turtlebot3\_slam turtlebot3\_slam.launch slam\_methods:=gmapping
	\item roslaunch turtlebot3\_teleop turtlebot3\_teleop\_key.launch
\end{itemize}

\subsection{Comunicación}

Para establecer la comunicación entre los robots y la computadora central, se deben seguir los siguientes pasos.

%Ilustración 1: Creación de una nueva red en Ubuntu.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.72]{imagenes/Implementacion/Procesamiento/01_Creacion_de_red.jpg}}
	\caption{Creación de una nueva red en Ubuntu.}
	\label{fig:Figura_Creacion_de_red}
\end{figure}

También es necesario configurar la red de la computadora remota como un punto de acceso, creando una nueva red, mostrada en la Figura \ref{fig:Figura_Creacion_de_red}. Posteriormente se debe seleccionar el tipo de conexión, tal y como se muestra en la \textit{Figura \ref{fig:Figura_Tipo_de_conexion}}.

%Ilustración 2: Elegir tipo de conexión.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.6]{imagenes/Implementacion/Procesamiento/02_Tipo_de_conexion.jpg}}
	\caption{Elegir tipo de conexión.}
	\label{fig:Figura_Tipo_de_conexion}
\end{figure}

Por último se editan las pestañas de las configuraciones inalámbricas y de seguridad como se muestran en las \textit{Figuras \ref{fig:Figura_Configuracion_de_nombre}} y                                \textit{\ref{fig:Figura_Configuracion_de_seguridad}}.

%Ilustración 3: Configuración del Modo y Nombre.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/03_Configuracion_de_nombre.jpg}}
	\caption{Configuración del modo y nombre.}
	\label{fig:Figura_Configuracion_de_nombre}
\end{figure}

%Ilustración 4: Configuración de la seguridad.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/04_Configuracion_de_seguridad.jpg}}
	\caption{Configuración de la seguridad.}
	\label{fig:Figura_Configuracion_de_seguridad}
\end{figure}

Una vez establecida la comunicación, se procede a realizar pruebas para determinar si la comunicación fue establecida correctamente. Para ello, se utiliza el comando \textit{ping} de la terminal de Linux que envía paquetes de forma continua a cada robot, como se muestra en la \textit{Figura \ref{fig:Figura_Comando_ping}}.

%Ilustración 5: Muestra del resultado correcto de la ejecución del comando ping.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.625]{imagenes/Implementacion/Procesamiento/05_Comando_ping.jpg}}
	\caption{Muestra del resultado correcto de la ejecución del comando ping.}
	\label{fig:Figura_Comando_ping}
\end{figure}

Como se apreciar en la \textit{Figura \ref{fig:Figura_Comando_ping}}, la comunicación fue establecida correctamente, ya que se recibieron todos los paquetes apropiadamente. Finalmente se prueba la comunicación de algunos tópicos simples para verificar que la configuración entre la red y ROS sea correcta, para ello se inicializa por medio de la computadora remota un TurtleBot3, además, con apoyo de la herramienta Rqt se puede visualizar el valor actual de algunos tópicos como por ejemplo, el estado de la batería mostrado en la \textit{Figura \ref{fig:Figura_RQt_topico_bateria}}.

%Ilustración 6: RQt mostrando los datos del tópico battery.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/06_RQt_topico_bateria.jpg}}
	\caption{RQt mostrando los datos del tópico battery.}
	\label{fig:Figura_RQt_topico_bateria}
\end{figure}

Todos los algoritmos de control son programados en el lenguaje de programación Python, siguiendo la lógica que fue propuesta en los diagramas de flujo posteriormente analizados. Los programas son almacenados en un mismo paquete llamado \textit{esquema\_lider\_seguidor}, con el objetivo de mantener en orden la información.
Para manejar la información de manera independiente, es necesario agrupar todos los tópicos por namespaces propios de cada robot, debido a que en un principio cada robot posee tópicos con el mismo nombre y en caso de no usarse los namespace para diferenciar a los tópicos,  resultaría muy complejo controlar los robots de forma individual, ya que no se podría distinguir si la información es enviada al líder o es enviada al seguidor.

\subsection{Prueba A: Verificación de la matriz de fuerza}

El objetivo es verificar si la matriz de fuerza fue hecha de manera correcta, comprobándola con un código que reconstruye la trayectoria a partir de la matriz; si la trayectoria tiene la forma original, se puede decir que fue hecha correctamente. Las \textit{Figuras \ref{fig:Figura_Reconstruccion_trayectoria_A}, \ref{fig:Figura_Reconstruccion_trayectoria_B}} y \textit{\ref{fig:Figura_Reconstruccion_trayectoria_C}} muestran la reconstrucción de la trayectoria, mientras que las \textit{Figuras \ref{fig:Figura_Puntos_de_trayectoria_A}, \ref{fig:Figura_Puntos_de_trayectoria_B}} y \textit{\ref{fig:Figura_Reconstruccion_trayectoria_C}} muestran la trayectoria original.

%Ilustración 7. Reconstrucción de la trayectoria A.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/07_Reconstruccion_trayectoria_A.jpg}}
	\caption{Reconstrucción de la trayectoria A.}
	\label{fig:Figura_Reconstruccion_trayectoria_A}
\end{figure}

%Ilustración 8. Reconstrucción de la trayectoria B.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/08_Reconstruccion_trayectoria_B.jpg}}
	\caption{Reconstrucción de la trayectoria B.}
	\label{fig:Figura_Reconstruccion_trayectoria_B}
\end{figure}

%Ilustración 9. Reconstrucción de la trayectoria C.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/09_Reconstruccion_trayectoria_C.jpg}}
	\caption{Reconstrucción de la trayectoria C.}
	\label{fig:Figura_Reconstruccion_trayectoria_C}
\end{figure}

%Ilustración 10. Puntos de trayectoria A.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/10_Puntos_trayectoria_A.jpg}}
	\caption{Puntos de trayectoria A.}
	\label{fig:Figura_Puntos_de_trayectoria_A}
\end{figure}

%Ilustración 11. Puntos de trayectoria B.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/11_Puntos_trayectoria_B.jpg}}
	\caption{Puntos de trayectoria B.}
	\label{fig:Figura_Puntos_de_trayectoria_B}
\end{figure}

%Ilustración 12. Puntos de trayectoria C.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/12_Puntos_trayectoria_C.jpg}}
	\caption{Puntos de trayectoria C.}
	\label{fig:Figura_Puntos_de_trayectoria_C}
\end{figure}

\subsubsection{Análisis de resultados}
En las \textit{Figuras \ref{fig:Figura_Reconstruccion_trayectoria_A}, \ref{fig:Figura_Reconstruccion_trayectoria_B}, \ref{fig:Figura_Reconstruccion_trayectoria_C}, \ref{fig:Figura_Puntos_de_trayectoria_A}, \ref{fig:Figura_Puntos_de_trayectoria_B}} y \textit{\ref{fig:Figura_Puntos_de_trayectoria_C}} se puede observar que la reconstrucción conserva la forma de la trayectoria, lo cual indica que las matrices están hechas correctamente.

\subsection{Prueba B: Validar el seguimiento de trayectoria}

Una vez verificada la matriz de fuerzas, se procede a la verificación del seguimiento de trayectoria. La prueba se hace en Gazebo como primera instancia para saber si el algoritmo funcionaba correctamente, pudiéndose apreciar visualmente como el robot sigue la trayectoria de manera adecuada, para posteriormente realizar la prueba física. Una vez hecho esto, se ejecute el programa con \textit{``roslaunch esquema\_lider\_seguidor lider.launch"} por medio de la computadora remota iniciando la recabación de datos de las posiciones con el comando, \textit{``rosrecord tb3\_0/amcl\_pose tb3\_1/amcl\_pose"}. Los datos que se recabados son usados para calcular el error que existe entre los puntos por cuales fue definida la trayectoria originalmente y los puntos por los que el robot pasó realmente, mostrados en las \textit{Figuras \ref{fig:Figura_Error_lider_A}, \ref{fig:Figura_Error_lider_B}} y \textit{\ref{fig:Figura_Grafica_posiciones_alcanzadas}}.

%Ilustración 13. Error del líder en seguimiento de la trayectoria A.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/13_Error_liderA.jpg}}
	\caption{Error del líder en seguimiento de la trayectoria A.}
	\label{fig:Figura_Error_lider_A}
\end{figure}

%Ilustración 14. Error del líder en seguimiento de la trayectoria B.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/14_Error_lider_B.jpg}}
	\caption{Error del líder en seguimiento de la trayectoria B.}
	\label{fig:Figura_Error_lider_B}
\end{figure}

%Ilustración 15. Gráfica de las posiciones alcanzadas y el error.
.\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/15_Grafica_posiciones_alcanzadas.jpg}}
	\caption{Gráfica de las posiciones alcanzadas y el error.}
	\label{fig:Figura_Grafica_posiciones_alcanzadas}
\end{figure}

\subsubsection{Análisis de resultados}

Se observa en las \textit{Figuras \ref{fig:Figura_Error_lider_A}, \ref{fig:Figura_Error_lider_B}} y \textit{\ref{fig:Figura_Grafica_posiciones_alcanzadas}} como el error disminuye y posteriormente se mantiene dentro de un umbral de 7 cm, indicando que el seguimiento de trayectoria efectivamente es ejecutado y realmente se hace un seguimiento de trayectoria.

\subsection{Prueba C: Validar el algoritmo Líder-Seguidor}

En las pruebas de la simulación del algoritmo líder-seguidor, se puede ver como el robot seguidor en ocasiones realiza los movimientos del líder con un desfase en la posición, por lo que se aplica
una condición de distancia mínima para permitir cambiar la dirección del robot, una vez actualizada la posición del seguidor, logrando así un mejor seguimiento de los puntos de coordenada y sin afectar por su posición actual.

%Ilustración 16. Error del seguidor en la trayectoria A.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/16_Error_Seguidor_A.jpg}}
	\caption{Error del seguidor en la trayectoria A.}
	\label{fig:Figura_Error_Seguidor_A}
\end{figure}

%Ilustración 17. Error del seguidor en la trayectoria B.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/Procesamiento/17_Error_Seguidor_B.jpg}}
	\caption{Error del seguidor en la trayectoria B.}
	\label{fig:Figura_Error_Seguidor_B}
\end{figure}

\subsubsection{Análisis de resultados}

Se toman nuevamente los datos de posición, en este caso las del seguidor \textit{Figuras \ref{fig:Figura_Error_Seguidor_A}} y \textit{\ref{fig:Figura_Error_Seguidor_B}}, y de igual manera, se obtiene un error respecto a la trayectoria. Dicho error valida que tan efectivo es el seguimiento de la trayectoria por parte del robot seguidor.

\subsection{Prueba D: Validar la evasión de obstáculos}

El algoritmo para la evasión de obstáculos se volvió la parte más compleja durante la implementación, debido a que, al haber reducido el área de trabajo propuesta en dimensiones por cuestiones de espacio en el área de trabajo real, los robots no lograba esquivar los objetos de manera correcta. El problema radicó en que todas las paredes del espacio de trabajo eran leídas como obstáculos y no se lograba establecer un camino adecuado para la evasión. Para solucionar esta problemática se creó un nodo adicional, encargado de calcular una distancia mínima para ciertos ángulos del robot, informándole al nodo principal si se debía leer o no el Histograma, para posteriormente aplicar el algoritmo Vector Field Histogram (VFH). \\

La forma de verificar el funcionamiento del código es a través de Gazebo, el cual inicializa el nodo y posteriormente corroboraba la información que envía el nodo con las posiciones de los obstáculos.

%Ilustración 18. Nodo Laser_Distance.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.365]{imagenes/Implementacion/Procesamiento/18_Diagrama_de_Flujo_Obstacle.jpg}}
	\caption{Método para calcular la distancia mínima y publicarla.}
	\label{fig:Figura_Nodo_laser_distance}
\end{figure}

En el programa donde se implementó el VFH fue necesario validarlo colocando obstáculos en el ambiente de simulación, y corroborando que el histograma efectivamente reflejara la posición angular de los obstáculos respecto al robot. Las \textit{Figuras \ref{fig:Figura_Deteccion_obstaculo_A}} y \textit{\ref{fig:Figura_Deteccion_obstaculo_B}} muestran los resultados las pruebas.

%Ilustración 19. Detección del obstáculo cercano colocado en el primer cuadrante.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.8]{imagenes/Implementacion/Procesamiento/19_Deteccion_obstaculo_A.jpg}}
	\caption{Detección del obstáculo cercano colocado en el primer cuadrante.}
	\label{fig:Figura_Deteccion_obstaculo_A}
\end{figure}

%Ilustración 20. Detección del obstáculo cercano colocado en el segundo cuadrante.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.8]{imagenes/Implementacion/Procesamiento/20_Deteccion_obstaculo_B.jpg}}
	\caption{Detección del obstáculo cercano colocado en el cuarto cuadrante.}
	\label{fig:Figura_Deteccion_obstaculo_B}
\end{figure}

Al integrar los nuevos nodos junto con el código del seguimiento de trayectoria, es necesario primeramente implementar la matriz de fuerza que permite al nodo saber la orientación que debe tomar el robot, de tal manera que este pueda mantenerse dentro de la trayectoria propuesta. Este algoritmo es programado en un método llamado \textit{``Follow"} mostrado en la \textit{Figura \ref{fig:Figura_Algoritmo_seguimiento_parte_A}}. Una vez conocida la posición, se discretiza en un a matriz para poder ser accedida, dado que es una matriz discretizada para evitar un error de índices en la programación, se definen los límites máximos y mínimos, tomando en cuenta las dimensiones del mapa. Con los índices definidos se procede a extraer la diferencia entre el punto de origen del robot y el punto al que se desea llegar, en caso de que no se haya seleccionado una trayectoria el robot se detiene.

%Ilustración 21. Algoritmo de seguimiento de trayectoria parte A.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.45]{imagenes/Implementacion/Procesamiento/21_Diagrama_Metodo_Follow.jpg}}
	\caption{Función Follow para ejecutar VFH o seguimiento de trayectoria.}
	\label{fig:Figura_Algoritmo_seguimiento_parte_A}
\end{figure}

Para incluir el algoritmo encargado de la evasión de los obstáculos, se propone obtener una distancia mínima como la mostrada en la \textit{Figura \ref{fig:Figura_Nodo_laser_distance}}, con la cual se decide si se inicia la evasión o no. En caso de tenerse una distancia mayor a la propuesta, se ejecuta el algoritmo de la \textit{Figura \ref{fig:Figura_Algoritmo_seguimiento_parte_B}}, el cual tiene como propósito el alineamiento del ángulo deseado, con la orientación propia del robot para posteriormente comparar dicho ángulo con su complemento y así determinar el sentido en el que debe girar el robot.

Debido a que el sistema puede dar oscilaciones muy grandes y con esto dañar los motores, se incluyen condiciones para que la velocidad angular quede dentro de un margen, de tal manera que si es muy grande el ángulo de error (45°) la velocidad lineal se vuelve cero, garantizando la rotación en su propio eje para cambios angulares grandes. Estas velocidades son publicadas para que el robot tome estos valores de velocidad.

%Ilustración 22. Algoritmo de seguimiento de trayectoria parte B.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.3475]{imagenes/Implementacion/Procesamiento/22_Diagrama_Metodo_Move.jpg}}
	\caption{Función de seguimiento de trayectoria por dirección.}
	\label{fig:Figura_Algoritmo_seguimiento_parte_B}
\end{figure}

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.43]{imagenes/Implementacion/Procesamiento/23_Diagrama_Metodo_VFH.jpg}}
	\caption{Algoritmo para aplicar VFH.}
	\label{fig:Figura_Algoritmo_seguimiento_parte_C}
\end{figure}

En el caso de que la distancia sea menor a la propuesta, como se muestra en la \textit{Figura \ref{fig:Figura_Algoritmo_seguimiento_parte_C}} se verifica si no hay un obstáculo en la dirección por la que el robot debe pasar, de no haber obstáculo sobre el ángulo deseado, se ejecuta la rutina anterior con el mismo ángulo indicado por la trayectoria, en caso contrario, se hace un mapeo antihorario y con 15° más (para evitar posibles futuras colisiones), con el objetivo de encontrar algún otro camino libre y alinear a los robots con base en la nueva trayectoria, publicando la nueva velocidad. 
%Ilustración 23. Algoritmo de seguimiento de trayectoria parte C.

\subsubsection{Validación de seguimiento y evasión}
La forma de validar los algoritmos de seguimiento de trayectorias consiste en una serie de pasos; inicialmente los robots fueron simulados en un ambiente virtual (gazebo), que incluye información sobre el espacio físico y funcional de los TurtleBot3 burger, igualando a las condiciones reales. La inspección a la prueba consiste en observar el comportamiento de los robots en la simulación, dando especial énfasis al seguimiento de la trayectoria, que de no colisionar con ningún obstáculo virtual que pudiera haber en el camino, se confirma que todo ha sido realizado de manera correcta para posteriormente llevar a cabo las pruebas físicas. Durante las pruebas físicas se guardan los datos de posición, que, junto con los datos de la trayectoria a seguir, y aplicando un algoritmo basado en un árbol kd se obtiene un error que valida la operación. 

Finalmente, para validar el algoritmo de evasión de obstáculos se colocan dos obstáculos en la zona de pruebas y se ejecuta el algoritmo de seguimiento de trayectoria, el algoritmo líder-seguidor y el algoritmo evasión. Para cada trayectoria los robots dan 3 recorridos, si falla únicamente una sola vez se considera exitoso.

\break

\subsection{Prueba E: Validar la integración de evasión y seguimiento}
El objetivo de esta prueba es validar el funcionamiento del sistema en conjunto; el algoritmo líder-seguidor y el algoritmo de evasión, realizándose una serie de pruebas en el ambiente real, que consisten en colocar a ambos robots (a medio metro de distancia entre ellos) y dos obstáculos en posiciones de la trayectoria por las que el robot líder debe de pasar. Debido al seguimiento de trayectoria, se realiza 3 recorridos para cada trayectoria, en donde si únicamente colisiona una vez por trayectoria, se considera válido. En las \textit{Figuras \ref{fig:25_Lider}} y \textit{\ref{fig:26_Seguidor}} se muestra el error obtenido en esta prueba.

%Ilustración 25. Algoritmo de seguimiento de trayectoria parte C.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.375]{imagenes/Implementacion/Procesamiento/25_errorLider-evasion.png}}
	\caption{Error del robot líder durante la evasión.}
	\label{fig:25_Lider}
\end{figure}

%Ilustración 26. Algoritmo de seguimiento de trayectoria parte D.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.375]{imagenes/Implementacion/Procesamiento/26_errorSeguidor-evasion.png}}
	\caption{Error del robot seguidor durante la evasión.}
	\label{fig:26_Seguidor}
\end{figure}

\subsubsection{Análisis de resultados}
Como se puede observar en las \textit{Figuras \ref{fig:25_Lider}} y \textit{\ref{fig:26_Seguidor}}, el error disminuye cuando se mantiene dentro de la trayectoria y aumenta cuando se requiere alejarse e iniciar la evasión. Para ambos robots el comportamiento es el mismo, lo cual valida que realmente existe una evasión, ya que el robot líder toma como prioridad el no chocar que el de mantenerse sobre la trayectoria.

\subsection{Realización de la HMI}

Para lograr que el sistema tenga una mejor interacción con el usuario, se lleva a cabo la implementación de una interfaz gráfica HMI \textit{(Human Machine Interface)}, con el fin de que usuario puede interactuar con los robots y comunicarles que acciones tomar (como la selección de la trayectoria a seguir).

Dadas estas características, se utiliza el ambiente de trabajo \textit{QtCreator} en el cual además de tener una extensa documentación e información de ayuda, ha sido utilizado para desarrollar una de las principales herramientas para el análisis de la información que posee el ecosistema de ROS, logrando que por medio de una interfaz \textit{rqt} realizada en \textit{Qt}, la visualización de las conexiones entre nodos, los valores de los distintos tópicos, el mando información con el fin de probar las diferentes variables de los tópicos, la graficación de la información de los nodos a través del tiempo, entre muchas otras funciones.

%%Ilustración 1: RQt para graficar distintos tópicos contra del tiempo.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=3]{imagenes/Implementacion/HMI/01_RQt_Graficas.jpg}}
	\caption{RQt para graficar distintos tópicos con respecto al tiempo.}
	\label{fig:Figura_RQt_Graficas}
\end{figure}

%%Ilustración 2: RQt mostrando y filtrando los distintos tipos de mensajes.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=2.7]{imagenes/Implementacion/HMI/02_RQt_Mensajes.jpg}}
	\caption{RQt mostrando y filtrando los distintos tipos de mensajes.}
	\label{fig:Figura_RQt_Mensajes}
\end{figure}

Con el objetivo de usar Qt, dada su versatilidad con ROS como herramienta gráfica para mandar órdenes a los robots líder y seguidor, se hacen uso de los siguientes paquetes:

\begin{itemize}
	\item qtcreator
	\item ros-kinetic-qt-create
	\item ros-kinetic-qt-build
\end{itemize}

Para la instalación de Qt Creator en una computadora con Ubuntu 16.04, se hacen uso de las siguientes instrucciones en la terminal de comandos de Ubuntu.

\begin{itemize}
	\item sudo apt-get install qtcreator
	\item sudo apt-get install ros-kinetic-qt-create
	\item sudo apt-get install ros-kinetic-qt-build
\end{itemize}

Una vez instalado se crean los paquetes que se describen en la página web de ROS, en la sección \textit{qt\_build} \cite{qt_build}. Cabe mencionar que para generar el paquete de ROS relacionado con la interfaz se hace uso de la instrucción en la terminal para la carpeta catkin\_ws de la siguiente forma.

\begin{itemize}
	\item catkin\_create\_qt\_pkg gui\_lider\_seguidor
\end{itemize}

Donde \textit{``catkin\_create\_qt\_pkg"}, es la instrucción para generar el paquete y \textit{``gui\_lider\_seguidor"}, es el nombre del paquete asignado por el usuario.\\

Una vez compilado correctamente el paquete de la interfaz, se puede compilar como cualquier otro paquete usando la instrucción \textit{catkin\_make} y si esta instrucción realiza la compilación correctamente entonces se puede editar y compilar el proyecto usando qtcreator. Para esto se ejecuta en la terminal el comando \textit{qtcreator} y este comando abre el programa qtcreator como se muestra en la \textit{Figura \ref{fig:Figura_Interfaz_Incio}}.

%%Ilustración 3: Inicio de QtCreator
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.2]{imagenes/Implementacion/HMI/03_Inicio_QtCreator.jpg}}
	\caption{Pantalla de bienvenida de QtCreator.}
	\label{fig:Figura_Inicio_QtCreator}
\end{figure}

Una vez dentro del programa, se abre el proyecto dando clic en ``File" luego ``Open File or Project", abriéndose un archivo``CmakeList.txt" del paquete creado, en este caso ``gui\_lider\_seguidor", como se muestra en la \textit{Figura \ref{fig:Figura_Abrir_GUI}}.

%%Ilustración 4: Ventana para compilar paquete en QtCreator.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.38]{imagenes/Implementacion/HMI/04_Abrir_GUI.jpg}}
	\caption{Ventana para compilar paquete en QtCreator.}
	\label{fig:Figura_Abrir_GUI}
\end{figure}

Posteriormente se abre una ventana para elegir las opciones de compilación donde se selecciona la carpeta en la cual se guardará la compilación, aquí se selecciona la carpeta ``build" dentro de la carpeta ``catkin\_ws", como se muestra en la \textit{Figura \ref{fig:Figura_Seleccionar_carpeta_compilacion}}.

%%Ilustración 5: Ingreso de la carpeta de compilación.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.5]{imagenes/Implementacion/HMI/05_Seleccionar_carpeta_compilacion.jpg}}
	\caption{Ingreso de la carpeta de compilación.}
	\label{fig:Figura_Seleccionar_carpeta_compilacion}
\end{figure}

Al darle ``next", aparecerá una ventana que pide el comando de compilación cmake, para que compile se le ingresa el siguiente comando en ``Arguments", el cual le indica como y donde compilar:

\begin{itemize}
	\item cmake ../src -DCMAKE\_INSTALL\_PREFIX=../install -DCATKIN\_DEVEL\_PREFIX=../devel
\end{itemize}

Este comando se puede consultar más a detalle en la sección ``catkin\_make" de la wiki de ROS \cite{catkin_make}.

Posteriormente se le da clic en el botón \textit{``Run CMake"}, compilando el proyecto con esta acción y al darle \textit{``Finish"} abriéndose los archivos relacionados con el proyecto si se compiló correctamente para poderse editar, como se muestra en la \textit{Figura \ref{fig:Figura_Qt_CMake}}.

%%Ilustración 6: Ingreso y compilación con el comando CMake.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.515]{imagenes/Implementacion/HMI/06_Qt_CMake.jpg}}
	\caption{Ingreso y compilación con el comando CMake.}
	\label{fig:Figura_Qt_CMake}
\end{figure}

Una vez realizado esto exitosamente, se muestra una ventana como la de la \textit{Figura \ref{fig:Figura_Ventana_Proyecto_QT}}. Cabe mencionar que este procedimiento se puede aplicar para cualquier paquete de la carpeta ``catkin\_ws".

%%Ilustración 7: Ventana en Qt con el paquete qgui.
\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.33]{imagenes/Implementacion/HMI/07_Ventana_Proyecto_QT.jpg}}
	\caption{Ventana en Qt con el paquete qgui.}
	\label{fig:Figura_Ventana_Proyecto_QT}
\end{figure}

La edición del paquete se describe a detalle en la wiki de ROS, sección de ``qt\_build" \cite{qt_build}, pero en resumen se divide en 4 partes.

\begin{itemize}
	\item El programa principal del proyecto.
	\item El programa de la funcionalidad del código de la ventana gráfica.
	\item El programa de las funciones para interactuar con ROS.
	\item El framework para realizar la edición de la HMI gráficamente.
\end{itemize}

Estos 3 programas y el framework de edición, trabajan en conjunto y cada uno está contenido dentro de otro de mayor nivel como se explica a continuación.

\subsubsection{Programa Principal}

El programa principal se encarga de crear el objeto de la ventana y que esta sea visible, además que cuando esta se cierra da la indicación que el programa ha terminado, esto al igual que los demás programas anteriormente mencionados también usa hilos de ejecución por medio de la librería QThread, para que puedan ejecutarse varios procesos a la vez dentro de un mismo código, logrando de tal forma que el usuario pueda interactuar con la interfaz al mismo tiempo que esta realiza distintos cálculos o envía mensajes al ecosistema de ROS en los tiempos adecuados. Este programa en general contiene todo porque de aquí llaman a los demás programas anteriormente mencionados.

\subsubsection{Ventana Gráfica}

Este programa muestra la interfaz gráfica creada en el framework de edición de Qt y al ser un programa de c++ se compone de 2 archivos el \textit{``main\_window.cpp"}, y el \textit{``main\_window.hpp"}. En el primero se le informa que variables van a existir dentro de la clase y que métodos se van a definir y en el segundo se le da la funcionalidad a cada uno de los métodos, del tal manera en esta parte del programa se programan que acciones van a realizar los elementos colocados en la interfaz gráfica, por ejemplo cuando se selecciona una opción de la trayectoria en la interfaz creada para este proyecto se muestra una imagen de la trayectoria, implicando esto que al inicializarse esta ventana lee la imagen y luego la guarda para después mostrarla y en general este proceso de lectura, guardado y ejecución se implementa a lo largo de todo este programa. Cabe mencionar que este programa es afectado por lo que se edita en el framework o editor de la interfaz gráfica y este programa de la ventana gráfica está contenido dentro del Programa Principal.

\subsubsection{Programa de ROS}

Este programa al igual que el anterior se compone de 2 archivos el \textit{``qnode .cpp"}, y el \textit{``qnode.hpp"}, los cuales hacen una clase dando funcionalidad y manejan definiciones de la clase respectivamente. En cuanto a lo que realiza este programa es inicializar la comunicación con ROS cuando le es pedido desde la interfaz gráfica, lo cual al ser manejado por un hilo de ejecución no bloquea la interfaz gráfica, también aquí se crea el nodo para trabajar con ROS, se definen a que tópicos se suscribe este nodo, que tópicos publica y además se definen métodos públicos que pueden ser llamados por la interfaz gráfica para realizar una cierta acción en el entorno de ROS. Cabe mencionar que este programa está contenido dentro del programa de la ventana gráfica y por defecto contiene el sistema de llamado de mensajes de consola de ROS.

\subsubsection{Framework de Trabajo}

El framework de trabajo es una herramienta muy útil, ya que se puede editar fácilmente y de manera interactiva como se visualizará la interfaz, destacando 2 ventajas: la primera que queda visualmente como se bosqueja la interfaz gráfica en vez de modificar posiciones o contenedores para que se ajusten y la segunda que sin un gran conocimiento de todas las librerías de la interfaz gráfica se puedan usar los elementos provistos por el framework que además de todo mejoran los tiempos de desarrollo de la interfaz, ya que se auto genera el código de la visualización de la interfaz y solo queda por programar su funcionalidad. Cabe mencionar que este framework crea un archivo que está contenido en el programa de la ventana gráfica para que los elementos queden justo como en el editor de la interfaz el cual se muestra en la \textit{Figura \ref{fig:Figura_Editor_Qt}}.

%Ilustración 8: Framework de Qt para GUI.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.3]{imagenes/Implementacion/HMI/08_Editor_Qt.jpg}}
	\caption{Framework de Qt para GUI.}
	\label{fig:Figura_Editor_Qt}
\end{figure}

\subsubsection{Puntos importantes a considerar}

Como recomendación se propone primero editar la interfaz gráfica sin intentar añadir un slot (método a ejecutar cada que hay un evento en cierto elemento de la interfaz; por ejemplo, darle clic a un pushbutton) a los componentes, ya que daña el proyecto al generar código erróneo, posteriormente compilarlo y después con este procedimiento ya aparecerán los nuevos componentes reconocidos automáticamente por el sistema para así realizar una mejor edición del código. En el caso de usar slots para darle funcionalidad a cada componente se recomienda conectarlos manualmente como se muestra en la siguiente instrucción:

\begin{itemize}
	\item QObject::connect(ui.pushButton\_Graficar, SIGNAL(clicked()),
	\item this, SLOT(pushButton\_Graficar\_clicked()));
\end{itemize}

Donde \textit{``ui.pushButton\_Graficar"}, es el botón en la interfaz gráfica, \textit{``clicked()"}, es la acción de darle clic a ese botón y \textit{``pushButton\_Graficar\_clicked()"}, es la acción que se ejecutará al darle clic en el botón \textit{``ui.pushButton\_Graficar"}.

\subsubsection{Modificación del Programa}

Dado que este paquete ya viene con una funcionalidad predeterminada, se modifica el código base, así como también la interfaz gráfica para ajustarlo a los requerimientos del trabajo, con lo cual, siguiendo la lógica del programa descrita anteriormente, se consigue enviar los tópicos necesarios para que se logre la interacción con los robots y la graficación. Los tópicos que se crean para dar dicha funcionalidad son los siguientes:

\begin{itemize}
	\item lane de tipo std\_msgs::Int32 para seleccionar la trayectoria.
	\item turn\_on de tipo std\_msgs::Bool para decidir si los móviles avanzan.
	\item graph de tipo std\_msgs::Bool para decidir si se grafica.
	\item clear\_graph de tipo std\_msgs::Bool para limpiar la gráfica y puntos almacenados.
	\item save\_data de tipo std\_msgs::Bool para guardar los datos graficados.
\end{itemize}

\subsubsection{Resultados de la ejecución}

A continuación, se muestran los resultados de la ejecución de la interfaz, donde destacan 3 ventanas principales.

\begin{itemize}
	\item Ventana para elegir trayectoria y encender o apagar al robot.
	\item Ventana para visualizar el historial de la trayectoria elegida.
	\item Ventana para graficar, limpiar gráficas o guardar datos.
\end{itemize}

En la primera ventana como se muestra en las \textit{Figuras \ref{fig:Figura_Interfaz_Incio}} y \textit{\ref{fig:Figura_Interfaz_Trayectoria1}} se elige la trayectoria deseada por el usuario pudiéndose ver la imagen de la trayectoria a seguir, sin embargo esta es cargada hasta que se presiona el botón \textit{cargar trayectoria}.

%%Ilustración 9: Configuración de la interfaz sin Trayectoria seleccionada.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.28]{imagenes/Implementacion/HMI/09_Interfaz_Incio.jpg}}
	\caption{Ventana inicial de la interfaz.}
	\label{fig:Figura_Interfaz_Incio}
\end{figure}

%Ilustración 10: Configuración de la interfaz con trayectoria 1 seleccionada y apagado.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.28]{imagenes/Implementacion/HMI/10_Interfaz_Trayectoria1.jpg}}
	\caption{Configuración de la interfaz con la trayectoria 1 seleccionada y apagada.}
	\label{fig:Figura_Interfaz_Trayectoria1}
\end{figure}

Para darle a los robots la instrucción de ``avanzar", se selecciona la opción encendido apareciendo en ese momento la opción marcada, comenzando los robots a seguir la trayectoria escogida como se muestra en las \textit{Figuras \ref{fig:Figura_Interfaz_Trayectoria2}} y \textit{\ref{fig:Figura_Interfaz_Trayectoria3}}, para apagarlo basta con volver a presionar el botón.

%Ilustración 11: Configuración de la interfaz con trayectoria 2 seleccionada y encendido.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/HMI/11_Interfaz_Trayectoria2.jpg}}
	\caption{Configuración de la interfaz con la trayectoria 2 seleccionada y encendida.}
	\label{fig:Figura_Interfaz_Trayectoria2}
\end{figure}

%Ilustración 12: Configuración de la interfaz con trayectoria 3 seleccionada y encendido.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/HMI/12_Interfaz_Trayectoria3.jpg}}
	\caption{Configuración de la interfaz con la trayectoria 3 seleccionada y encendida.}
	\label{fig:Figura_Interfaz_Trayectoria3}
\end{figure}

En la segunda ventana se muestra el historial de todas las trayectorias cargadas, así como los mensajes de prueba para verificar que la interfaz este enviando bien la información a través de ROS \textit{(Figura \ref{fig:Figura_Interfaz_Mensajes})} sin nunca haberse cargado alguna trayectoria y en la \textit{Figura \ref{fig:Figura_Interfaz_Mensajes_2}} con un historial de trayectorias cargadas (donde además se puede consultar cual es la trayectoria a seguir actualmente).

%Ilustración 13: Interfaz con los mensajes de prueba enviados.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.34]{imagenes/Implementacion/HMI/13_Interfaz_Mensajes.jpg}}
	\caption{Interfaz con los mensajes de prueba enviados.}
	\label{fig:Figura_Interfaz_Mensajes}
\end{figure}

%Ilustración 14: Interfaz con el historial de trayectorias seleccionadas.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.34]{imagenes/Implementacion/HMI/14_Interfaz_Mensajes.jpg}}
	\caption{Interfaz con el historial de trayectorias seleccionadas.}
	\label{fig:Figura_Interfaz_Mensajes_2}
\end{figure}

En la tercera ventana como se observa en la \textit{Figura \ref{fig:Figura_Interfaz_Graficar}} se dan las opciones para controlar la graficación. Si se quiere limpiar la gráfica para realizar varios guardados sin repetir la información, y para guardar los datos de los valores de posición y error en un archivo con formato .npy y .xlsx .

%Ilustración 15: Interfaz mostrando las opciones de graficación.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.25]{imagenes/Implementacion/HMI/15_Interfaz_Graficar.jpg}}
	\caption{Interfaz mostrando las opciones de graficación.}
	\label{fig:Figura_Interfaz_Graficar}
\end{figure}

\section{Especificaciones del Sistema}

En esta sección se habla de las especificaciones de algunos de los componentes de cada área funcional como los tiempos de las baterías LiPo, los diagramas de nodos y las dimensiones del área de una manera breve.

\subsubsection{Especificaciones del Área de Trabajo}

El Área de Trabajo fue fabricada de MDF y sus dimensiones son las siguientes: 2.4m x 2.4m x .30m (Longitud - Ancho - Altura).

\subsubsection{Especificaciones de la Alimentación}

Cada batería de los robots dura aproximadamente \textit{dos horas} de uso continuo, y tarda en cargarse aproximadamente \textit{una hora y media}.

\subsubsection{Especificaciones del Procesamiento}
En la Figura \ref{fig:Nodos_Rosgraph} se muestran la red de nodos implementada para el proyecto.

\begin{figure}[H]
	\centering
	\fbox{\includegraphics[scale=0.155]{imagenes/Implementacion/Especificaciones/01_rosgraph_node.jpg}}
	\caption{Nodos de Rosgraph.}
	\label{fig:Nodos_Rosgraph}
\end{figure}